{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question auto-encoder \n",
    "\n",
    "In this notebook we'll try to train a LSTM auto-encoder by feeding the questions and targeting the same input.\n",
    "\n",
    "This way we'll try to extract some representation of the questions that will permit us to extract then the questions that have the same structure through clusterization.\n",
    "\n",
    "### How will the LSTM auto-encoder be trained?\n",
    "* by feeding the question **tokens** and targeting the input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- question: string (nullable = true)\n",
      " |-- answer: string (nullable = true)\n",
      " |-- image_id: string (nullable = true)\n",
      " |-- tokenized_question: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- question_len: double (nullable = true)\n",
      " |-- question_word_len: double (nullable = true)\n",
      " |-- first_word: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from keras.preprocessing.sequence import *\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"QuestionRephrasing-AutoEncoder\") \\\n",
    "    .config(\"spark.executor.memory\", \"5G\")\\\n",
    "    .config(\"spark.driver.memory\", \"10G\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"5G\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setCheckpointDir('data/checkpoints')\n",
    "questions = spark.read.parquet(\"data/processed/union/*\")\n",
    "questions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Maximum characters length is 238 and maximum word length is 28.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's extract now the maximum token length of every question\n",
    "# We'll need those later for sequence padding\n",
    "max_word_len = int(questions.agg({\"question_word_len\": \"max\"}).collect()[0][\"max(question_word_len)\"])\n",
    "\n",
    "f\"Maximum question word length is {max_word_len}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary build\n",
    "\n",
    "We need to extract a numerical representation of *words*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Word mapping example for 'is': 1.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokens vocabulary and mappers\n",
    "tokens = questions.select('tokenized_question')\\\n",
    "    .rdd\\\n",
    "    .flatMap(lambda x: x['tokenized_question'])\\\n",
    "    .collect()\n",
    "\n",
    "word_mapping = {}\n",
    "word_mapping_reversed = {}\n",
    "word_counter = Counter(tokens)\n",
    "for idx, value in enumerate(word_counter):\n",
    "    word_mapping[value] = idx\n",
    "    word_mapping_reversed[idx] = value\n",
    "    \n",
    "f\"Word mapping example for 'is': {word_mapping['is']}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input pre-processing\n",
    "\n",
    "Now let's pre-process the input to have the corresponding **mappings** for *words*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(question='what is this photo taken looking through?', answer='net', image_id='458752', tokenized_question=['what', 'is', 'this', 'photo', 'taken', 'looking', 'through', '?'], question_len=41.0, question_word_len=8.0, first_word='what', question_char_embeddings=[[1], [2], [3], [4], [5], [6], [7], [5], [4], [2], [6], [7], [5], [8], [2], [9], [4], [9], [5], [4], [3], [10], [11], [12], [5], [13], [9], [9], [10], [6], [12], [14], [5], [4], [2], [15], [9], [16], [14], [2], [17]], question_word_embeddings=[[1], [2], [3], [4], [5], [6], [7], [8]])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_word_embeddings = F.udf(lambda tokenized_question: [[word_mapping[word] + 1] for word in tokenized_question], ArrayType(ArrayType(IntegerType())))\n",
    "\n",
    "questions = questions.withColumn('question_word_embeddings', extract_word_embeddings(F.col('tokenized_question')))\n",
    "questions.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4],\n",
       "        [5],\n",
       "        [6],\n",
       "        [7],\n",
       "        [8],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings = questions.select('question_word_embeddings')\\\n",
    "    .rdd\\\n",
    "    .map(lambda x: x['question_word_embeddings'])\\\n",
    "    .collect()\n",
    "word_embeddings = pad_sequences(word_embeddings, maxlen=max_word_len, dtype='int32', padding='post', truncating='pre', value=0.0)\n",
    "word_embeddings[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_31 (LSTM)               (None, 50)                10400     \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "repeat_vector_16 (RepeatVect (None, 28, 100)           0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 28, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_32 (LSTM)               (None, 28, 28)            14448     \n",
      "_________________________________________________________________\n",
      "time_distributed_16 (TimeDis (None, 28, 1)             29        \n",
      "=================================================================\n",
      "Total params: 29,977\n",
      "Trainable params: 29,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoding_dim = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(encoding_dim, activation='relu', input_shape=(max_word_len, 1), dropout=0.25, recurrent_dropout=0.25))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(100))\n",
    "model.add(RepeatVector(max_word_len))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(max_word_len, activation='relu', return_sequences=True, dropout=0.25, recurrent_dropout=0.25))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.compile(optimizer=opt, loss='mse', metrics=['mae', 'accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1327111 samples, validate on 568763 samples\n",
      "Epoch 1/10\n",
      "1327111/1327111 [==============================] - 449s 339us/step - loss: 539198.5773 - mae: 145.5489 - accuracy: 0.3212 - val_loss: 367301.0000 - val_mae: 96.4138 - val_accuracy: 0.2496\n",
      "\n",
      "Epoch 00001: saving model to model-checkpoints/autoencoder-words/autoencoder-model-01-0.25.hdf5\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrluc/Documents/facultate/disertatie/workspace/venv/lib/python3.7/site-packages/keras/engine/saving.py:165: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "  'TensorFlow optimizers do not '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1327111/1327111 [==============================] - 598s 451us/step - loss: 438773.9831 - mae: 124.7340 - accuracy: 0.3199 - val_loss: 348571.8285 - val_mae: 85.0832 - val_accuracy: 0.2622\n",
      "\n",
      "Epoch 00002: saving model to model-checkpoints/autoencoder-words/autoencoder-model-02-0.26.hdf5\n",
      "Epoch 3/10\n",
      "1327111/1327111 [==============================] - 468s 353us/step - loss: 393966.9928 - mae: 113.5677 - accuracy: 0.3079 - val_loss: 345325.0377 - val_mae: 80.1916 - val_accuracy: 0.2370\n",
      "\n",
      "Epoch 00003: saving model to model-checkpoints/autoencoder-words/autoencoder-model-03-0.24.hdf5\n",
      "Epoch 4/10\n",
      "1327111/1327111 [==============================] - 469s 354us/step - loss: 378992.2908 - mae: 107.7284 - accuracy: 0.1791 - val_loss: 345827.9217 - val_mae: 81.6884 - val_accuracy: 0.0895\n",
      "\n",
      "Epoch 00004: saving model to model-checkpoints/autoencoder-words/autoencoder-model-04-0.09.hdf5\n",
      "Epoch 5/10\n",
      "1327111/1327111 [==============================] - 570s 429us/step - loss: 370278.8864 - mae: 103.8514 - accuracy: 0.0388 - val_loss: 341952.4661 - val_mae: 79.2061 - val_accuracy: 0.0605\n",
      "\n",
      "Epoch 00005: saving model to model-checkpoints/autoencoder-words/autoencoder-model-05-0.06.hdf5\n",
      "Epoch 6/10\n",
      "1327111/1327111 [==============================] - 590s 445us/step - loss: 361197.6558 - mae: 100.6310 - accuracy: 0.0363 - val_loss: 344038.0573 - val_mae: 80.6033 - val_accuracy: 0.0320\n",
      "\n",
      "Epoch 00006: saving model to model-checkpoints/autoencoder-words/autoencoder-model-06-0.03.hdf5\n",
      "Epoch 7/10\n",
      "1327111/1327111 [==============================] - 415s 313us/step - loss: 358087.8008 - mae: 98.3494 - accuracy: 0.0354 - val_loss: 341175.9902 - val_mae: 84.1245 - val_accuracy: 0.0292\n",
      "\n",
      "Epoch 00007: saving model to model-checkpoints/autoencoder-words/autoencoder-model-07-0.03.hdf5\n",
      "Epoch 8/10\n",
      "1327111/1327111 [==============================] - 520s 392us/step - loss: 354660.4674 - mae: 95.8459 - accuracy: 0.0338 - val_loss: 339822.6681 - val_mae: 76.4604 - val_accuracy: 0.0306\n",
      "\n",
      "Epoch 00008: saving model to model-checkpoints/autoencoder-words/autoencoder-model-08-0.03.hdf5\n",
      "Epoch 9/10\n",
      "1327111/1327111 [==============================] - 548s 413us/step - loss: 352015.3037 - mae: 93.8745 - accuracy: 0.0317 - val_loss: 339065.1404 - val_mae: 74.4140 - val_accuracy: 0.0395\n",
      "\n",
      "Epoch 00009: saving model to model-checkpoints/autoencoder-words/autoencoder-model-09-0.04.hdf5\n",
      "Epoch 10/10\n",
      "1327111/1327111 [==============================] - 416s 313us/step - loss: 351725.6338 - mae: 92.8388 - accuracy: 0.0299 - val_loss: 339119.2149 - val_mae: 71.3592 - val_accuracy: 0.0211\n",
      "\n",
      "Epoch 00010: saving model to model-checkpoints/autoencoder-words/autoencoder-model-10-0.02.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a1966f90>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"model-checkpoints/autoencoder-words/autoencoder-model-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(word_embeddings, word_embeddings,\n",
    "                epochs=10,\n",
    "                batch_size=1000,\n",
    "                shuffle=True,\n",
    "                callbacks=callbacks_list,\n",
    "                validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
