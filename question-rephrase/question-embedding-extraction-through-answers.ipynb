{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Embedding extraction through VQA without images\n",
    "\n",
    "In this notebook we're going to use a Recursive Neural Network for generating Question embeddings based on the question format and it's answer.\n",
    "\n",
    "The goal of this is to extract array representation for the questions where similar questions are close."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- question: string (nullable = true)\n",
      " |-- answer: string (nullable = true)\n",
      " |-- image_id: string (nullable = true)\n",
      " |-- tokenized_question: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- question_len: double (nullable = true)\n",
      " |-- question_word_len: double (nullable = true)\n",
      " |-- first_word: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1895874"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from keras.preprocessing.sequence import *\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"QuestionRephrasing-AutoEncoder\") \\\n",
    "    .config(\"spark.executor.memory\", \"5G\")\\\n",
    "    .config(\"spark.driver.memory\", \"10G\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"5G\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setCheckpointDir('data/checkpoints')\n",
    "questions = spark.read.parquet(\"data/processed/union/*\")\n",
    "questions.printSchema()\n",
    "questions.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mmaximum word length is 28.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_word_len = int(questions.agg({\"question_word_len\": \"max\"}).collect()[0][\"max(question_word_len)\"])\n",
    "\n",
    "f\"Mmaximum number of word in a question is {max_word_len}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Word mapping example for 'is': 1.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokens vocabulary and mappers\n",
    "tokens = questions.select('tokenized_question')\\\n",
    "    .rdd\\\n",
    "    .flatMap(lambda x: x['tokenized_question'])\\\n",
    "    .collect()\n",
    "\n",
    "word_mapping = {}\n",
    "word_mapping_reversed = {}\n",
    "word_counter = Counter(tokens)\n",
    "for idx, value in enumerate(word_counter):\n",
    "    word_mapping[value] = idx\n",
    "    word_mapping_reversed[idx] = value\n",
    "    \n",
    "f\"Word mapping example for 'is': {word_mapping['is']}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the word representation of input using the mapping above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(question='what is this photo taken looking through?', answer='net', image_id='458752', tokenized_question=['what', 'is', 'this', 'photo', 'taken', 'looking', 'through', '?'], question_len=41.0, question_word_len=8.0, first_word='what', question_word_embeddings=[1, 2, 3, 4, 5, 6, 7, 8])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_word_embeddings = F.udf(lambda tokenized_question: [word_mapping[word] + 1 for word in tokenized_question], ArrayType(IntegerType()))\n",
    "\n",
    "questions = questions.withColumn('question_word_embeddings', extract_word_embeddings(F.col('tokenized_question')))\n",
    "questions.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4, 5, 6, 7, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings = questions.select('question_word_embeddings')\\\n",
    "    .rdd\\\n",
    "    .map(lambda x: x['question_word_embeddings'])\\\n",
    "    .collect()\n",
    "word_embeddings = pad_sequences(word_embeddings, maxlen=max_word_len, dtype='int32', padding='post', truncating='pre', value=0.0)\n",
    "word_embeddings[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the answers targets to one-hot representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_tokens = questions.select('answer')\\\n",
    "    .rdd\\\n",
    "    .map(lambda x: x['answer'])\\\n",
    "    .collect()\n",
    "\n",
    "nr_answers = len(set(answer_tokens))\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(answer_tokens)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "\n",
    "y = onehot_encoder.fit_transform(integer_encoded)\n",
    "y[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for extracting question embeddings\n",
    "\n",
    "**Input:** question embedded (each token represents a number according to the above mapping) as sequences and padded\n",
    "\n",
    "**Output:** answers as one-hot\n",
    "\n",
    "For extracting the question embeddings, we'll train the model and then we'll drop the last layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 28, 5)             115365    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 28, 5)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 28, 10)            60        \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 20)                1680      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 215205)            2367255   \n",
      "=================================================================\n",
      "Total params: 2,484,570\n",
      "Trainable params: 2,484,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_mapping) + 1, 5, input_length=max_word_len, mask_zero=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(10))\n",
    "model.add(Bidirectional(LSTM(10, activation='relu', dropout=0.1, recurrent_dropout=0.1), input_shape=(max_word_len, 5)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(nr_answers, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute answers class weights\n",
    "\n",
    "Since there are lots of answers the dataset is very imbalanced. Thus for optimizing the training we're providing class weights so the model can adjust based on how many times the answer appeared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "classes = list(set(answer_tokens))\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes, answer_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = list(zip(label_encoder.fit_transform(classes), class_weights))\n",
    "weights.sort(key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training and checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrluc/Documents/facultate/disertatie/workspace/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1327111 samples, validate on 568763 samples\n",
      "Epoch 1/3\n",
      "  15000/1327111 [..............................] - ETA: 10:14:44 - loss: 12.2783 - accuracy: 0.0132   "
     ]
    }
   ],
   "source": [
    "filepath=\"model-checkpoints/answer-embeddings/answer-embeddings-model-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "model.fit(word_embeddings, [y],\n",
    "                epochs=3,\n",
    "                batch_size=5000,\n",
    "                shuffle=True,\n",
    "                callbacks=callbacks_list,\n",
    "                class_weight=weights,\n",
    "                validation_split=0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
